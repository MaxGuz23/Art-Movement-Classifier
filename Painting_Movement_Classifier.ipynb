{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Painting_Movement_Classifier_2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QTRxNa_BEY10",
        "Qh7X2lkFEeuz",
        "nOxKyLItEhiv",
        "CZiyzeRXElgt",
        "LIS7cR40Esoc",
        "Ifl1h3vbR27c",
        "CiMq3PCLR_Fq",
        "ouSAQrSPIQ3i",
        "E5mT51KGDV-X",
        "lxnSUkhWD-t9",
        "XHHVzeR2KoVf",
        "GlsFVN1LKte7"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries and setup"
      ],
      "metadata": {
        "id": "QTRxNa_BEY10"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boPEno1pDB59"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import * \n",
        "\n",
        "import os\n",
        "\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.python.keras.layers.core import Flatten\n",
        "\n",
        "# from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Colab setup"
      ],
      "metadata": {
        "id": "Qh7X2lkFEeuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "H9IbpfZoDOg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read csv"
      ],
      "metadata": {
        "id": "nOxKyLItEhiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Proyecto_Final/artists_clean.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "v9gOe10FDOek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variables setup"
      ],
      "metadata": {
        "id": "CZiyzeRXElgt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Artists dictionary"
      ],
      "metadata": {
        "id": "LIS7cR40Esoc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qecttypahx6y"
      },
      "outputs": [],
      "source": [
        "# dict of artist in each folder\n",
        "# Post_Impressionism/Vincent_van_Gogh/Vincent_van_Gogh_1.jpg\n",
        "\n",
        "# Kazimir_Malevich/Kazimir_Malevich_112.jpg\n",
        "# Cubism\n",
        "# /content/drive/MyDrive/Proyecto_Final/pictures/images/images/Renaissance/Leonardo_da_Vinci\n",
        "artist_per_genre = {\n",
        "    'Abstract':['Paul_Klee',\n",
        "                'Vasiliy_Kandinskiy',\n",
        "                'Joan_Miro',\n",
        "                'Jackson_Pollock'],\n",
        "    'Baroque':['Caravaggio', \n",
        "               'Peter_Paul_Rubens', \n",
        "               'Rembrandt'],\n",
        "    'Expresionism':['Amedeo_Modigliani', \n",
        "                    'Edvard_Munch',\n",
        "                    'Marc_Chagall'],\n",
        "    'Renaissance':['Leonardo_da_Vinci',\n",
        "                     'Michelangelo',\n",
        "                     'Raphael',\n",
        "                     'Titian',\n",
        "                   'Albrecht_DuÌˆrer',\n",
        "                     'Hieronymus_Bosch',\n",
        "                     'Jan_van_Eyck',\n",
        "                     'Pieter_Bruegel',\n",
        "                   'Sandro_Botticelli'],\n",
        "    'Impressionism':['Alfred_Sisley',\n",
        "                     'Camille_Pissarro',\n",
        "                     'Claude_Monet',\n",
        "                     'Edgar_Degas',\n",
        "                     'Georges_Seurat',\n",
        "                     'Henri_de_Toulouse-Lautrec',\n",
        "                     'Paul_Cezanne',\n",
        "                     'Pierre-Auguste_Renoir',\n",
        "                     'Vincent_van_Gogh'],\n",
        "    'Realism':['Edouard_Manet',\n",
        "               'Gustave_Courbet'],\n",
        "    'Romanticism':['Eugene_Delacroix',\n",
        "                   'Francisco_Goya',\n",
        "                   'William_Turner'],\n",
        "    'Surrealism':['Frida_Kahlo',\n",
        "                  'Henri_Rousseau',\n",
        "                  'Rene_Magritte',\n",
        "                  'Salvador_Dali'],\n",
        "    'Cubism':['Kazimir_Malevich',\n",
        "              'Pablo_Picasso']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genres = list(artist_per_genre.keys())"
      ],
      "metadata": {
        "id": "6c6bVMvxH3Mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Path to artists folders"
      ],
      "metadata": {
        "id": "Ifl1h3vbR27c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Proyecto_Final/pictures/images/images'"
      ],
      "metadata": {
        "id": "MIUx0pDUDOZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Networks variables\n"
      ],
      "metadata": {
        "id": "CiMq3PCLR_Fq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (180, 180, 3)"
      ],
      "metadata": {
        "id": "Lx-tR2-zMPTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_qty = 9"
      ],
      "metadata": {
        "id": "nWXa8KZpNbY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouSAQrSPIQ3i"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0ME-i-HGgSL"
      },
      "outputs": [],
      "source": [
        "def jpg_to_dic(artist, painting_quantity=10):\n",
        "    \"\"\"\n",
        "    This function returns a dictionary containing the arrays corresponding to \n",
        "    each painting of the artist.\n",
        "\n",
        "    The image file name must be: <artist>_<number>.jpg\n",
        "    e.g. Salvador_Dali_13.jpg\n",
        "    \"\"\"\n",
        "\n",
        "    dic = dict()\n",
        "\n",
        "    for paint_num in range(1, painting_quantity+1):\n",
        "        painting = f'{relative_path}{artist}_{paint_num}.jpg'\n",
        "\n",
        "        img = tf.keras.preprocessing.image.load_img(painting, \n",
        "        grayscale=False, \n",
        "        color_mode=\"rgb\", \n",
        "        target_size=(180, 180), \n",
        "        interpolation=\"nearest\"\n",
        "        )\n",
        "        array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "        dic[paint_num] = array\n",
        "    print('\\nDone!\\n')\n",
        "    return dic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRIn0-M6Gk90"
      },
      "outputs": [],
      "source": [
        "def jpg_to_array(artists, painting_quantity=10):\n",
        "    \"\"\"\n",
        "    This function returns a dictionary containing the arrays corresponding to \n",
        "    each painting of the artist.\n",
        "\n",
        "    The image file name must be: <artist>_<number>.jpg\n",
        "    e.g. Salvador_Dali_13.jpg\n",
        "    \"\"\"\n",
        "\n",
        "    lst = list()\n",
        "\n",
        "    for paint_num in range(1, painting_quantity+1):\n",
        "        painting = f'{relative_path}{artist}_{paint_num}.jpg'\n",
        "\n",
        "        img = tf.keras.preprocessing.image.load_img(painting, \n",
        "        grayscale=False, \n",
        "        color_mode=\"rgb\", \n",
        "        target_size=(180, 180), \n",
        "        interpolation=\"nearest\"\n",
        "        )\n",
        "        array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "        lst.append(array)\n",
        "    print('\\nDone!\\n')\n",
        "    return lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMVwa1gyG6nq"
      },
      "outputs": [],
      "source": [
        "def get_df(dictionary, artist, artist_number, size=97200):\n",
        "  \"\"\"\n",
        "  This function takes the dictionary and an artist name and returns a pandas\n",
        "  dataframe of the paintings array with the label in the last column\n",
        "  \"\"\"\n",
        "  # df = pd.DataFrame() # Empty DataFrame\n",
        "  DF = pd.DataFrame(dictionary[artist][1].reshape(1, size))\n",
        "  for painting in dictionary[artist]: #range(1,4):#\n",
        "    # print(painting)\n",
        "    if painting != 10:\n",
        "      DF_2 = pd.DataFrame(dictionary[artist][painting+1].reshape(1, size))\n",
        "      DF = pd.concat([DF, DF_2])\n",
        "    else:\n",
        "      continue\n",
        "  DF['Y'] = artist_number\n",
        "  print('\\nDone!\\n')\n",
        "  return DF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOOGvEweIxpA"
      },
      "outputs": [],
      "source": [
        "def painting_arrays(n):\n",
        "  \"\"\"\n",
        "  This function returns a list of n number of paintings from the artists\n",
        "  \"\"\"\n",
        "  arrays_list = list()\n",
        "  # artist_array_dict = dict()\n",
        "  for artist, qty in zip(artists, paint_qty):\n",
        "    print(artist)\n",
        "    # artist_array_dict[artist] = jpg_to_array(artist, n)\n",
        "    arrays_list.append(jpg_to_array(artist, 10))\n",
        "  print('\\nDone!\\n')\n",
        "  return arrays_list#, artist_array_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRL6_2LYgyj0"
      },
      "outputs": [],
      "source": [
        "def jpg_to_array_from_folders(path, genre, painting_quantity=10):\n",
        "    \"\"\"\n",
        "    This function returns a list containing the arrays corresponding to \n",
        "    each painting of the genre folder.\n",
        "\n",
        "    The image file name must be: <artist>_<number>.jpg\n",
        "    e.g. Salvador_Dali_13.jpg\n",
        "    \"\"\"\n",
        "\n",
        "    lst = list()\n",
        "\n",
        "    for paint_num in range(1, painting_quantity+1):\n",
        "        painting = f'{path}{genre}_{paint_num}.jpg'\n",
        "\n",
        "        img = tf.keras.preprocessing.image.load_img(painting, \n",
        "        grayscale=False, \n",
        "        color_mode=\"rgb\", \n",
        "        target_size=(180, 180), \n",
        "        interpolation=\"nearest\"\n",
        "        )\n",
        "        array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "        lst.append(array)\n",
        "    print('\\nDone!\\n')\n",
        "    return lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqF1GsT4hUVP"
      },
      "outputs": [],
      "source": [
        "def arrays_from_genre(path, genre, genre_dict=artist_per_genre, painting_quantity=10, target_size=(180, 180)):\n",
        "  \"\"\"\n",
        "  This function returns a list containing the arrays of images from a path.\n",
        "  The folders contains artists folders as this:\n",
        "\n",
        "  images:\n",
        "    genre_1:\n",
        "      artist_1:\n",
        "        img_1.jpg\n",
        "        img_2.jpg\n",
        "        img_3.jpg\n",
        "      artist_2:\n",
        "        img_1.jpg\n",
        "        img_2.jpg\n",
        "        img_3.jpg\n",
        "    genre_2:\n",
        "      artist_1:\n",
        "        img_1.jpg\n",
        "        img_2.jpg\n",
        "        img_3.jpg\n",
        "      artist_2:\n",
        "        img_1.jpg\n",
        "        img_2.jpg\n",
        "        img_3.jpg\n",
        "  \"\"\"\n",
        "  arrays_genre = list()\n",
        "\n",
        "  list_artists = artist_per_genre[genre] # list of artists\n",
        "  # iterate over list of artists\n",
        "  for artist in list_artists:\n",
        "    print(f' Currently in {genre}, {artist} ')\n",
        "    for paint_num in range(1, painting_quantity+1):\n",
        "      \n",
        "      painting = f'{path}/{genre}/{artist}/{artist}_{paint_num}.jpg'\n",
        "\n",
        "      img = tf.keras.preprocessing.image.load_img(painting, \n",
        "      grayscale=False, \n",
        "      color_mode=\"rgb\", \n",
        "      target_size=target_size, \n",
        "      interpolation=\"nearest\"\n",
        "      )\n",
        "      array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "      arrays_genre.append(array)\n",
        "\n",
        "  print('\\nDone!\\n')\n",
        "  return arrays_genre"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# path = '/content/drive/MyDrive/Proyecto_Final/pictures/images/images'\n",
        "def paintings_to_predict(path, dic=artist_per_genre, train_samples=20, predict_samples=5, target_size=(180, 180)):\n",
        "\n",
        "  array_predict = list()\n",
        "\n",
        "  genres = list(dic.keys())\n",
        "  rd_genre = random.choice(genres)\n",
        "  # print(rd_genre)\n",
        "  list_artists = dic[rd_genre]\n",
        "\n",
        "  rd_artist = random.choice(list_artists)\n",
        "  max_paint = 30\n",
        "  top_paint = train_samples+predict_samples\n",
        "  \n",
        "  if top_paint > max_paint:\n",
        "    rd_paint = random.randint(train_samples+1, max_paint)\n",
        "  else:\n",
        "    rd_paint = random.randint(train_samples+1, top_paint)\n",
        "\n",
        "  painting = f'{path}/{rd_genre}/{rd_artist}/{rd_artist}_{rd_paint}.jpg'\n",
        "\n",
        "  img = tf.keras.preprocessing.image.load_img(painting, \n",
        "  grayscale=False, \n",
        "  color_mode=\"rgb\", \n",
        "  target_size=target_size, \n",
        "  interpolation=\"nearest\"\n",
        "  )\n",
        "  array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "  array_predict.append(array)\n",
        "\n",
        "  return (rd_artist, array)"
      ],
      "metadata": {
        "id": "YO5c6-y64P6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training graph\n",
        "def plot_training(history):\n",
        "    acc = history['acc']\n",
        "    val_acc = history['val_acc']\n",
        "    loss = history['loss']\n",
        "    val_loss = history['val_loss']\n",
        "    epochs = range(len(acc))\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15,5))\n",
        "    \n",
        "    axes[0].plot(epochs, acc, 'r-', label='Training Accuracy')\n",
        "    axes[0].plot(epochs, val_acc, 'b--', label='Validation Accuracy')\n",
        "    axes[0].set_title('Training and Validation Accuracy')\n",
        "    axes[0].legend(loc='best')\n",
        "\n",
        "    axes[1].plot(epochs, loss, 'r-', label='Training Loss')\n",
        "    axes[1].plot(epochs, val_loss, 'b--', label='Validation Loss')\n",
        "    axes[1].set_title('Training and Validation Loss')\n",
        "    axes[1].legend(loc='best')\n",
        "    \n",
        "    plt.show()\n",
        "    \n",
        "# plot_training(history)"
      ],
      "metadata": {
        "id": "MfMqVE0BK00x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_paintings(n_predictions, model=model):\n",
        "  \n",
        "  bullseye = 0\n",
        "  miss = 0\n",
        "  for n in range(n_predictions):\n",
        "\n",
        "    y_predict = paintings_to_predict(path)\n",
        "\n",
        "    prediction = model.predict(y_predict[1].reshape(1,180,180,3))\n",
        "    # prediction\n",
        "\n",
        "    for label, index in enumerate(list(prediction[0])):\n",
        "      if index == 1:\n",
        "        predicted_label = genres[label]\n",
        "      else:\n",
        "        pass\n",
        "    if y_predict[0] in artist_per_genre[predicted_label]:\n",
        "      print(f'The model predicted {predicted_label} for {y_predict[0]}. Prediction Correct! :D\\n')\n",
        "      bullseye += 1\n",
        "    else:\n",
        "      print(f'The model predicted {predicted_label} for {y_predict[0]}, Prediction Failed :(\\n')\n",
        "      miss += 1\n",
        "  return bullseye, miss"
      ],
      "metadata": {
        "id": "uz8A-cn2LtjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def paintings_array(path, painting_quantity=20):\n",
        "\n",
        "  \"\"\"\n",
        "  This function gets the list of paintings transformed to arrays.\n",
        "\n",
        "  Uses 'arrays_from_genre()'\n",
        "  \"\"\"\n",
        "\n",
        "  array_list = list()\n",
        "  # path = '/content/drive/MyDrive/Proyecto_Final/pictures/images/images'\n",
        "\n",
        "  for genre in artist_per_genre.keys():\n",
        "    array_list.append(arrays_from_genre(path, genre, painting_quantity=20))\n",
        "  print(f'Array size is: {len(array_list)}')\n",
        "  print('-----'*10)\n",
        "  return array_list"
      ],
      "metadata": {
        "id": "Y6ggIvpHDOXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_paintings_list(array_list):\n",
        "\n",
        "  \"\"\"\n",
        "  This function transforms the list of arrays into a numpy array\n",
        "  and print it's dimentions\n",
        "  \"\"\"\n",
        "\n",
        "  paintings_list = list()\n",
        "\n",
        "  for genre in array_list:\n",
        "    for artist in genre:\n",
        "      paintings_list.append(artist)\n",
        "\n",
        "  data_array = np.array(paintings_list)\n",
        "  print(f'the data array shape is: {data_array.shape}')\n",
        "  print('\\n-----'*10)\n",
        "  return data_array"
      ],
      "metadata": {
        "id": "RSnrmGSeDOUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# genres = list(artist_per_genre.keys())\n",
        "\n",
        "def get_labels(genres, data_array):\n",
        "  labels_codified = []\n",
        "  labels = []\n",
        "\n",
        "  for code, actual_genre in enumerate(genres):\n",
        "    for i in range(1, len(artist_per_genre[actual_genre])+1):\n",
        "      for j in range(20):\n",
        "        labels.append(actual_genre)\n",
        "        labels_codified.append(code)\n",
        "  print(f'The codified labels length is: {len(labels_codified)}. And here are the first 35 of them:\\n')\n",
        "  print(list(zip(labels, labels_codified))[0:35])\n",
        "  print()\n",
        "  print(f'\\nCodifed labels : Data array ---> {len(labels_codified), len(data_array)}\\n')\n",
        "  print(f'The shape of the codified labels array is: {np.array(labels_codified).shape}')\n",
        "  print('\\n-----'*10)\n",
        "\n",
        "  return labels_codified"
      ],
      "metadata": {
        "id": "xEbss7PxDORj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (180, 180, 3)\n",
        "def reescale_images(train_images, test_images, n_train, n_test, input_shape):\n",
        "  train_images = train_images.reshape(n_train, input_shape[0], input_shape[1], input_shape[2])\n",
        "  test_images = test_images.reshape(n_test, input_shape[0], input_shape[1], input_shape[2])\n",
        "  # Confirming the type of data\n",
        "  train_images = train_images.astype('float32')\n",
        "  test_images = test_images.astype('float32')\n",
        "  # Reescale the pixels between 0 and 255\n",
        "  train_images /= 255\n",
        "  test_images /= 255\n",
        "  return train_images, test_images"
      ],
      "metadata": {
        "id": "MUUTeCMQDOAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "E5mT51KGDV-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array_list = paintings_array(path, painting_quantity=20)"
      ],
      "metadata": {
        "id": "NT-iasO-GevF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_array = get_paintings_list(array_list)"
      ],
      "metadata": {
        "id": "cOvYOfRbHhk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_codified = get_labels(genres, data_array)"
      ],
      "metadata": {
        "id": "jRmhZy3sDOPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data_array\n",
        "y = np.array(labels_codified) #(num_list)\n",
        "# labels_qty = 9\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                    test_size=0.25,\n",
        "                                                    random_state=42)\n",
        "\n",
        "print(f'Train_test_split shapes: {x_train.shape, x_test.shape, y_train.shape, y_test.shape}\\n')\n",
        "\n",
        "# Uncoment [:,:,:,0] to transform RGB to GS\n",
        "train_images = x_train#[:,:,:,0]\n",
        "test_images = x_test#[:,:,:,0]\n",
        "train_labels = y_train\n",
        "test_labels = y_test\n",
        "# print(f'{train_images.shape, test_images.shape, train_labels.shape, test_labels.shape}')\n",
        "\n",
        "n_train = train_images.shape[0]\n",
        "n_test = test_images.shape[0]\n",
        "\n",
        "print(f'number of arrays: {n_train, n_test}\\n')"
      ],
      "metadata": {
        "id": "px-Lfg3NDOHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images, test_images = reescale_images(train_images, \n",
        "                                            test_images, \n",
        "                                            n_train, \n",
        "                                            n_test,\n",
        "                                            input_shape)"
      ],
      "metadata": {
        "id": "x3C68ahFMoJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dense ANN"
      ],
      "metadata": {
        "id": "lxnSUkhWD-t9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train a NN\n",
        "# def FFNN(train_images, train_labels, test_images, test_labels, labels_qty, epochs=30, batch_size=32):\n",
        "model = keras.Sequential([\n",
        "    layers.Flatten(),                      \n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dense(labels_qty, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy']\n",
        "              )\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=30, batch_size=32)\n",
        "\n",
        "print('Evaluation:\\n')\n",
        "model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "id": "FyuEqIj5DN-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FFNN(train_images, train_labels, test_images, test_labels, labels_qty, epochs=30, batch_size=32)"
      ],
      "metadata": {
        "id": "HMmuF1EeDN5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "id": "NQhMfL9qDN7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHHVzeR2KoVf"
      },
      "source": [
        "## Convolutional Neural Network (simple)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T02LnggeHtni"
      },
      "outputs": [],
      "source": [
        "# def simple_CNN(train_images, train_labels, test_images, test_labels, labels_qty, epochs=10, batch_size=32):\n",
        "model = keras.Sequential([\n",
        "    layers.Conv2D(180, 3, activation='relu', input_shape=input_shape), \n",
        "    # strides := velocity of the smaller grid\n",
        "    layers.Conv2D(90, 3, activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(labels_qty, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy']\n",
        "              )\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=32)\n",
        "print('Evaluation:\\n')\n",
        "model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# simple_CNN(train_images, train_labels, test_images, test_labels, labels_qty, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "id": "s5K1x9bKPlTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBc-K_7uH-sD"
      },
      "outputs": [],
      "source": [
        "# model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlsFVN1LKte7"
      },
      "source": [
        "## Convolutional Neural Network (custom)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    layers.AveragePooling2D(6, 3, input_shape=input_shape), \n",
        "    # strides := velocity of the smaller grid\n",
        "    layers.Conv2D(180*2, 3, activation='relu'),\n",
        "    layers.Conv2D(90*2, 3, activation='relu'),\n",
        "    layers.MaxPool2D(2,2),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(360*2, activation='relu'),\n",
        "    layers.Dense(labels_qty, activation='softmax')\n",
        "])\n",
        "optimizer = Adam(lr=0.0001)\n",
        "\n",
        "# model.compile(loss='categorical_crossentropy',\n",
        "#               optimizer=optimizer, \n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy']\n",
        "              )\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=25, batch_size=32)\n",
        "print('Evaluation:\\n')\n",
        "model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "id": "GVoi5XcXDNxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "id": "y6FAqljaEN-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicitions"
      ],
      "metadata": {
        "id": "NwmfiCWwAzUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict = paintings_to_predict(path)\n",
        "prediction = model.predict(y_predict[1].reshape(1,180,180,3))\n",
        "# list(prediction[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3RUQWGnD-0k",
        "outputId": "20d2e665-04f1-46b8-e32b-126941381f74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "wrEbk2FDSZD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_paintings(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eG4P1lwK-sQP",
        "outputId": "c5165e72-f964-4b2d-ba56-342350f10a7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model predicted Impressionism for Pablo_Picasso, Prediction Failed :(\n",
            "\n",
            "The model predicted Impressionism for Paul_Cezanne. Prediction Correct! :D\n",
            "\n",
            "The model predicted Abstract for Paul_Klee. Prediction Correct! :D\n",
            "\n",
            "The model predicted Impressionism for William_Turner, Prediction Failed :(\n",
            "\n",
            "The model predicted Impressionism for Peter_Paul_Rubens, Prediction Failed :(\n",
            "\n",
            "The model predicted Impressionism for Joan_Miro, Prediction Failed :(\n",
            "\n",
            "The model predicted Impressionism for Francisco_Goya, Prediction Failed :(\n",
            "\n",
            "The model predicted Impressionism for Peter_Paul_Rubens, Prediction Failed :(\n",
            "\n",
            "The model predicted Impressionism for Edgar_Degas. Prediction Correct! :D\n",
            "\n",
            "The model predicted Impressionism for Jackson_Pollock, Prediction Failed :(\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OPCFlPAqEOab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "i7odh_WCEOYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "J-dyxxaiEOV3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}